{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 验证码识别测试\n",
    "\n",
    "由于生成10000张图片的tfrecords耗费时间太长，先写入500张进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = ['a','b','c','d']\n",
    "print(li[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "def getOnehot(label):\n",
    "    # float64\n",
    "    label1 = np.zeros((40,))\n",
    "    for i in range(4):\n",
    "        label1[i*10+label[i]]=1\n",
    "    return label1\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "DIR = \"./CaptchaImage/\"\n",
    "\n",
    "def decodeJPG(filename, sess, writer):\n",
    "    image = tf.gfile.FastGFile(os.path.join(DIR, filename), 'rb').read()\n",
    "    # 将图片解码，解成张量  image is a 3-D uint8 or uint16 Tensor of shape [height, width, channels]\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    # 转化为灰度图\n",
    "    image = sess.run(tf.image.rgb_to_grayscale(image))\n",
    "    # 将图片转化为1维\n",
    "    # 这一步不run的话，返回tensor变量，run了之后返回ndarray\n",
    "    image = sess.run(tf.reshape(image, [-1]))\n",
    "    print(image.shape)\n",
    "    # 获得标签\n",
    "    names = filename.split('.')\n",
    "    lab= sess.run(tf.reshape([int(i) for i in list(names[0])],[-1]))\n",
    "    label = getOnehot(lab)\n",
    "    # 将一个验证码图片转化为Example Protocol Buffer\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'input_pixels_num': _int64_feature(160 * 60),\n",
    "        'label': _bytes_feature(label.tostring()),\n",
    "        'image': _bytes_feature(image.tostring())\n",
    "    }))\n",
    "    writer.write(example.SerializeToString())\n",
    "   \n",
    "          \n",
    "filename = \"./CaptchaRecognize/output.tfrecords\"\n",
    "          \n",
    "with tf.Session() as sess:\n",
    "    # 创建一个writer来写tfrecord文件\n",
    "    with tf.python_io.TFRecordWriter(filename) as writer:\n",
    "        for root, dirs, files in os.walk(DIR):\n",
    "            # 定义进度条\n",
    "            with tqdm(total=1000, desc='进度') as bar:\n",
    "                for file in files[0:1000]:\n",
    "                    decodeJPG(file, sess=sess, writer=writer)\n",
    "                    bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取tfrecords文件\n",
    "# 创建一个reader对象\n",
    "reader = tf.TFRecordReader()\n",
    "# 创建一个队列维护输入文件列表\n",
    "filename_queue = tf.train.string_input_producer([\"./CaptchaRecognize/output.tfrecords\"])\n",
    "_, serialized_example = reader.read(filename_queue)\n",
    "# 使用parse_single_example 一次只取一个数据\n",
    "# 使用parse_example 可以取多个\n",
    "feature = tf.parse_single_example(serialized_example,\n",
    "                                 features={\n",
    "        'input_pixels_num':tf.FixedLenFeature([],tf.int64),\n",
    "        'label': tf.FixedLenFeature([],tf.string),\n",
    "        'image': tf.FixedLenFeature([],tf.string) \n",
    "                                 })\n",
    "image = tf.decode_raw(feature['image'],tf.uint8)\n",
    "label = tf.decode_raw(feature['label'],tf.float64)\n",
    "# label = tf.reshape(tf.cast(label,tf.float32), [-1])\n",
    "pixnum = feature['input_pixels_num']\n",
    "sess = tf.Session()\n",
    "# # 启动多线程处理输入数据\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(5):\n",
    "#     img = sess.run(image)\n",
    "#     im = sess.run(tf.reshape(img,[60,160]))\n",
    "#     plt.figure(1)\n",
    "#     plt.imshow(im)\n",
    "#     plt.show()\n",
    "   print(sess.run([image,label]))\n",
    "\n",
    "# sess.close() 上面程序应该是自动关闭了sess，手动关闭会报错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建batch读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.decode_raw(feature['image'],tf.uint8)\n",
    "image.set_shape([9600])\n",
    "image = tf.cast(image,tf.float32)\n",
    "label = tf.decode_raw(feature['label'],tf.float64)\n",
    "label.set_shape([40])\n",
    "label = tf.cast(label,tf.float32)\n",
    "# sess = tf.Session()\n",
    "# #将数据转化为实数\n",
    "# img_data = tf.image.convert_image_dtype(image,dtype=tf.float32)\n",
    "# print(sess.run(img_data))\n",
    "# sess.close()\n",
    "# # 调整图像大小\n",
    "# image = tf.image.resize_images(img_data,[60,160],method=0)\n",
    "\n",
    "# sess.close()\n",
    "batch_size = 20\n",
    "capacity = 1000 + 3 * batch_size\n",
    "# input_queue = tf.train.slice_input_producer([image, label], shuffle=False) \n",
    "example_batch, label_batch = tf.train.batch(\n",
    "[image, label],batch_size= batch_size,capacity=capacity)\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    # 启动多线程处理输入数据\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "    for i in range(10):\n",
    "        cur_example_batch,cur_label_batch = sess.run([example_batch, label_batch])\n",
    "#         cur_example_batch,cur_label_batch = sess.run([image,label])\n",
    "        print(cur_example_batch,cur_label_batch)\n",
    "    print(cur_example_batch.shape)\n",
    "\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建卷积神经网络进行验证码图片的识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "filename = '0000'\n",
    "filename2 = '0020'\n",
    "names = filename.split('.')\n",
    "names2 = filename2.split('.')\n",
    "label = [int(i) for i in list(names[0])]\n",
    "label2 = [int(i) for i in list(names2[0])]\n",
    "l = tf.reshape(label,[-1])\n",
    "l2 = tf.reshape(label2,[-1])\n",
    "r1,r2 = sess.run([l,l2])\n",
    "print(r1,r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化权值\n",
    "def weight_variables(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# 初始化偏置值\n",
    "def bias_variables(shape):\n",
    "    initial = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "# 卷积层\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding=\"SAME\")\n",
    "# 池化层\n",
    "def max_pool_5x5():\n",
    "    return tf.nn.max_pool(x,ksize=[1,5,5,1],strides=[1,5,5,1],padding=\"SAME\")\n",
    "    \n",
    "# 池化\n",
    "def max_pool_4x4():\n",
    "    return tf.nn.max_pool(x,ksize=[1,4,4,1],strides=[1,4,4,1],padding=\"SAME\")\n",
    "\n",
    "x = tf.placeholder(tf.floa32,[None,9600])\n",
    "y = tf.placeholder(tf.float32,[None,4])\n",
    "\n",
    "# width 60 height 160 channel 1\n",
    "x_in = tf.reshape(x,[-1,60,160,1])\n",
    "\n",
    "W_conv1 =  weight_variables([5,5,1,16])\n",
    "b_conv1 = bias_variables([16])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_in,W_conv1)+b_conv1)\n",
    "h_pool1 = max_pool_5x5(h_conv1)\n",
    "\n",
    "W_conv2 =  weight_variables([5,5,16,32])\n",
    "b_conv2 = bias_variables([32])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2)+b_conv2)\n",
    "h_pool2 = max_pool_4x4(h_conv2)\n",
    "\n",
    "W_fc1 = weight_variables([3*8*32,120])\n",
    "b_fc1 = bias_variables([120])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2,[-1,3*8*32])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)\n",
    "keef_pro = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.dropout(h_fc1,keef_pro)\n",
    "\n",
    "W_fc2 = weight_variables([120,40])\n",
    "b_fc2 = bias_variables([40])\n",
    "\n",
    "prediction = tf.matmul(h_fc1_drop,W_fc2) + b_fc2\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(y,0),tf.argmax(prediction,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "image = tf.decode_raw(feature['image'],tf.uint8)\n",
    "image.set_shape([9600])\n",
    "image = tf.cast(image,tf.float32)\n",
    "label = tf.decode_raw(feature['label'],tf.int32)\n",
    "label.set_shape([4])\n",
    "label = tf.cast(label,tf.float32)\n",
    "\n",
    "batch_size = 100\n",
    "capacity = 1000 + 3 * batch_size\n",
    "example_batch, label_batch = tf.train.batch(\n",
    "[image, label],batch_size= batch_size,capacity=capacity)\n",
    "init = tf.initialize_all_variables()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "    for epoch in range(10):\n",
    "        for i in rage(10):\n",
    "            cur_example_batch,cur_label_batch = sess.run([example_batch, label_batch])\n",
    "#         cur_example_batch,cur_label_batch = sess.run([image,label])\n",
    "            print(cur_example_batch,cur_label_batch)\n",
    "            sess.run(train_step,feed_dict={x:cur_example_batch,y:cur_label_batch})\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
