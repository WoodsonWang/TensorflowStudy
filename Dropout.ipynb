{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 载入数据集  \"MNIST_data\"为数据集下载路径，\n",
    "# one_hot是图像的标签使用one_hot编码\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,Test-Accuracy0.7952,Train-Accuracy0.8026\n",
      "Epoch:1,Test-Accuracy0.8376,Train-Accuracy0.85383636\n",
      "Epoch:2,Test-Accuracy0.8596,Train-Accuracy0.88069093\n",
      "Epoch:3,Test-Accuracy0.8709,Train-Accuracy0.8956182\n",
      "Epoch:4,Test-Accuracy0.8771,Train-Accuracy0.9061818\n",
      "Epoch:5,Test-Accuracy0.88,Train-Accuracy0.91565454\n",
      "Epoch:6,Test-Accuracy0.8845,Train-Accuracy0.92236364\n",
      "Epoch:7,Test-Accuracy0.8893,Train-Accuracy0.928\n",
      "Epoch:8,Test-Accuracy0.8921,Train-Accuracy0.9335818\n",
      "Epoch:9,Test-Accuracy0.8968,Train-Accuracy0.9372\n",
      "Epoch:10,Test-Accuracy0.8942,Train-Accuracy0.9400182\n",
      "Epoch:11,Test-Accuracy0.897,Train-Accuracy0.9435818\n",
      "Epoch:12,Test-Accuracy0.8999,Train-Accuracy0.94676363\n",
      "Epoch:13,Test-Accuracy0.9013,Train-Accuracy0.95034546\n",
      "Epoch:14,Test-Accuracy0.9013,Train-Accuracy0.95305455\n",
      "Epoch:15,Test-Accuracy0.9019,Train-Accuracy0.9552909\n",
      "Epoch:16,Test-Accuracy0.901,Train-Accuracy0.9577091\n",
      "Epoch:17,Test-Accuracy0.9033,Train-Accuracy0.9601091\n",
      "Epoch:18,Test-Accuracy0.9031,Train-Accuracy0.9608\n",
      "Epoch:19,Test-Accuracy0.9034,Train-Accuracy0.9633818\n",
      "Epoch:20,Test-Accuracy0.9043,Train-Accuracy0.9639636\n"
     ]
    }
   ],
   "source": [
    "# 每个批次的大小\n",
    "batch_size = 100\n",
    "# 计算有多少个批次  // 为整除  10 // 3 = 3\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "# 用来接收Dropout参数\n",
    "keep_pro = tf.placeholder(tf.float32)\n",
    "\n",
    "weights1 = tf.Variable(tf.truncated_normal([784,100],stddev=1.0))\n",
    "biases1 = tf.Variable(tf.zeros([100])+0.1)\n",
    "L1 = tf.nn.tanh(tf.matmul(x,weights1)+biases1)\n",
    "L1_drop = tf.nn.dropout(L1,keep_pro)\n",
    "\n",
    "weights2 = tf.Variable(tf.truncated_normal([100,100],stddev=1.0))\n",
    "biases2 = tf.Variable(tf.zeros([100])+0.1)\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop,weights2)+biases2)\n",
    "L2_drop = tf.nn.dropout(L2,keep_pro)\n",
    "\n",
    "weights3 = tf.Variable(tf.truncated_normal([100,10],stddev=1.0))\n",
    "biases3 = tf.Variable(tf.zeros([10])+0.1)\n",
    "pre = tf.matmul(L2_drop,weights3)+biases3\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=pre))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(pre,1))\n",
    "# 求准确率\n",
    "# tf.cast 将correct_prediction 转化为32位的浮点型，True 转为 1 False 转为 0\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # keep_pro设置成1.0是节点全部工作  0.7则是有70%工作\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_pro:1.0})\n",
    "        acc_test = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_pro:1.0})\n",
    "        acc_train = sess.run(accuracy,feed_dict={x:mnist.train.images,y:mnist.train.labels,keep_pro:1.0})\n",
    "        print(\"Epoch:\"+str(epoch)+\",Test-Accuracy\"+str(acc_test)+\",Train-Accuracy\"+str(acc_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,Test-Accuracy0.7495,Train-Accuracy0.7418182\n",
      "Epoch:1,Test-Accuracy0.7753,Train-Accuracy0.77230906\n",
      "Epoch:2,Test-Accuracy0.7992,Train-Accuracy0.7964\n",
      "Epoch:3,Test-Accuracy0.8182,Train-Accuracy0.81165457\n",
      "Epoch:4,Test-Accuracy0.8235,Train-Accuracy0.8208909\n",
      "Epoch:5,Test-Accuracy0.8312,Train-Accuracy0.8283091\n",
      "Epoch:6,Test-Accuracy0.8315,Train-Accuracy0.82994545\n",
      "Epoch:7,Test-Accuracy0.8563,Train-Accuracy0.85225457\n",
      "Epoch:8,Test-Accuracy0.8642,Train-Accuracy0.8550182\n",
      "Epoch:9,Test-Accuracy0.8671,Train-Accuracy0.8626909\n",
      "Epoch:10,Test-Accuracy0.8773,Train-Accuracy0.86987275\n",
      "Epoch:11,Test-Accuracy0.8752,Train-Accuracy0.8679818\n",
      "Epoch:12,Test-Accuracy0.8802,Train-Accuracy0.8755091\n",
      "Epoch:13,Test-Accuracy0.8821,Train-Accuracy0.87734544\n",
      "Epoch:14,Test-Accuracy0.8845,Train-Accuracy0.88116366\n",
      "Epoch:15,Test-Accuracy0.8868,Train-Accuracy0.8827091\n",
      "Epoch:16,Test-Accuracy0.8884,Train-Accuracy0.88641816\n",
      "Epoch:17,Test-Accuracy0.891,Train-Accuracy0.88787276\n",
      "Epoch:18,Test-Accuracy0.8923,Train-Accuracy0.8909091\n",
      "Epoch:19,Test-Accuracy0.8943,Train-Accuracy0.8938182\n",
      "Epoch:20,Test-Accuracy0.8977,Train-Accuracy0.89527273\n"
     ]
    }
   ],
   "source": [
    "# 每个批次的大小\n",
    "batch_size = 100\n",
    "# 计算有多少个批次  // 为整除  10 // 3 = 3\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "# 用来接收Dropout参数\n",
    "keep_pro = tf.placeholder(tf.float32)\n",
    "\n",
    "weights1 = tf.Variable(tf.truncated_normal([784,100],stddev=1.0))\n",
    "biases1 = tf.Variable(tf.zeros([100])+0.1)\n",
    "L1 = tf.nn.tanh(tf.matmul(x,weights1)+biases1)\n",
    "L1_drop = tf.nn.dropout(L1,keep_pro)\n",
    "\n",
    "weights2 = tf.Variable(tf.truncated_normal([100,100],stddev=1.0))\n",
    "biases2 = tf.Variable(tf.zeros([100])+0.1)\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop,weights2)+biases2)\n",
    "L2_drop = tf.nn.dropout(L2,keep_pro)\n",
    "\n",
    "weights3 = tf.Variable(tf.truncated_normal([100,10],stddev=1.0))\n",
    "biases3 = tf.Variable(tf.zeros([10])+0.1)\n",
    "pre = tf.matmul(L2_drop,weights3)+biases3\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=pre))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(pre,1))\n",
    "# 求准确率\n",
    "# tf.cast 将correct_prediction 转化为32位的浮点型，True 转为 1 False 转为 0\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_pro:0.5})\n",
    "        acc_test = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_pro:1.0})\n",
    "        acc_train = sess.run(accuracy,feed_dict={x:mnist.train.images,y:mnist.train.labels,keep_pro:1.0})\n",
    "        print(\"Epoch:\"+str(epoch)+\",Test-Accuracy\"+str(acc_test)+\",Train-Accuracy\"+str(acc_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 当使用softmax_cross_entropy_with_logits，在计算正确率时是否需要对输出层使用softmax函数？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,Accuracy0.7973,Soft-Accuracy0.7973\n",
      "Epoch:1,Accuracy0.8373,Soft-Accuracy0.8373\n",
      "Epoch:2,Accuracy0.8582,Soft-Accuracy0.8582\n",
      "Epoch:3,Accuracy0.8678,Soft-Accuracy0.8678\n",
      "Epoch:4,Accuracy0.8765,Soft-Accuracy0.8765\n",
      "Epoch:5,Accuracy0.8829,Soft-Accuracy0.8829\n",
      "Epoch:6,Accuracy0.886,Soft-Accuracy0.886\n",
      "Epoch:7,Accuracy0.8872,Soft-Accuracy0.8872\n",
      "Epoch:8,Accuracy0.893,Soft-Accuracy0.893\n",
      "Epoch:9,Accuracy0.8983,Soft-Accuracy0.8983\n",
      "Epoch:10,Accuracy0.8988,Soft-Accuracy0.8988\n",
      "Epoch:11,Accuracy0.8968,Soft-Accuracy0.8968\n",
      "Epoch:12,Accuracy0.901,Soft-Accuracy0.901\n",
      "Epoch:13,Accuracy0.9015,Soft-Accuracy0.9015\n",
      "Epoch:14,Accuracy0.9027,Soft-Accuracy0.9027\n",
      "Epoch:15,Accuracy0.9009,Soft-Accuracy0.9009\n",
      "Epoch:16,Accuracy0.9038,Soft-Accuracy0.9038\n",
      "Epoch:17,Accuracy0.9034,Soft-Accuracy0.9034\n",
      "Epoch:18,Accuracy0.9025,Soft-Accuracy0.9025\n",
      "Epoch:19,Accuracy0.9055,Soft-Accuracy0.9055\n",
      "Epoch:20,Accuracy0.9042,Soft-Accuracy0.9042\n"
     ]
    }
   ],
   "source": [
    "# 每个批次的大小\n",
    "batch_size = 100\n",
    "# 计算有多少个批次  // 为整除  10 // 3 = 3\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "# 用来接收Dropout参数\n",
    "keep_pro = tf.placeholder(tf.float32)\n",
    "\n",
    "weights1 = tf.Variable(tf.truncated_normal([784,100],stddev=1.0))\n",
    "biases1 = tf.Variable(tf.zeros([100])+0.1)\n",
    "L1 = tf.nn.tanh(tf.matmul(x,weights1)+biases1)\n",
    "L1_drop = tf.nn.dropout(L1,keep_pro)\n",
    "\n",
    "weights2 = tf.Variable(tf.truncated_normal([100,100],stddev=1.0))\n",
    "biases2 = tf.Variable(tf.zeros([100])+0.1)\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop,weights2)+biases2)\n",
    "L2_drop = tf.nn.dropout(L2,keep_pro)\n",
    "\n",
    "weights3 = tf.Variable(tf.truncated_normal([100,10],stddev=1.0))\n",
    "biases3 = tf.Variable(tf.zeros([10])+0.1)\n",
    "pre = tf.matmul(L2_drop,weights3)+biases3\n",
    "\n",
    "prediction = tf.nn.softmax(pre)\n",
    "\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=pre))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(pre,1))\n",
    "correct_prediction_softmax = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "\n",
    "# 求准确率\n",
    "# tf.cast 将correct_prediction 转化为32位的浮点型，True 转为 1 False 转为 0\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "accuracy_softmax = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # keep_pro设置成1.0是节点全部工作  0.7则是有70%工作\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_pro:1.0})\n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_pro:1.0})\n",
    "        acc_softmax = sess.run(accuracy_softmax,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_pro:1.0})\n",
    "        print(\"Epoch:\"+str(epoch)+\",Accuracy\"+str(acc)+\",Soft-Accuracy\"+str(acc_softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
