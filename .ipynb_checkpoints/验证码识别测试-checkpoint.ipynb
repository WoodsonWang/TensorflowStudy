{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 验证码识别测试\n",
    "\n",
    "由于生成10000张图片的tfrecords耗费时间太长，先写入500张进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = ['a','b','c','d']\n",
    "print(li[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:   0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-47-7b8ee90c2f33>:10: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:   3%|▎         | 1/32 [00:04<02:10,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250 243 245 ... 243 242 253]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:   6%|▋         | 2/32 [00:04<01:29,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250 250 250 ... 250 250 250]\n",
      "[246 246 246 ... 249 245 243]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:   9%|▉         | 3/32 [00:04<01:02,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[245 246 237 ... 244 244 244]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "进度:  16%|█▌        | 5/32 [00:04<00:30,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[243 243 244 ... 244 244 244]\n",
      "[247 247 247 ... 247 247 247]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "进度:  22%|██▏       | 7/32 [00:05<00:16,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[247 247 247 ... 247 245 244]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  25%|██▌       | 8/32 [00:05<00:12,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[248 248 248 ... 248 248 248]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  28%|██▊       | 9/32 [00:05<00:10,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250 250 250 ... 250 250 250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  31%|███▏      | 10/32 [00:06<00:08,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[249 251 246 ... 251 251 251]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  34%|███▍      | 11/32 [00:06<00:07,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[245 245 245 ... 232 239 238]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  38%|███▊      | 12/32 [00:06<00:06,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[248 248 248 ... 248 248 248]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  41%|████      | 13/32 [00:06<00:06,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[251 251 251 ... 253 251 249]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  44%|████▍     | 14/32 [00:07<00:05,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[251 251 251 ... 251 251 251]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  47%|████▋     | 15/32 [00:07<00:05,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[235 247 245 ... 240 242 243]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  50%|█████     | 16/32 [00:07<00:04,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[247 247 248 ... 249 249 249]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  53%|█████▎    | 17/32 [00:08<00:04,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[249 243 250 ... 246 246 246]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  56%|█████▋    | 18/32 [00:08<00:03,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[249 246 243 ... 232 137  91]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  59%|█████▉    | 19/32 [00:08<00:03,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[245 245 245 ... 245 245 245]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  62%|██████▎   | 20/32 [00:08<00:03,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[244 239 238 ... 242 242 242]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  66%|██████▌   | 21/32 [00:09<00:03,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[246 246 246 ... 246 246 246]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  69%|██████▉   | 22/32 [00:09<00:03,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[243 243 243 ... 243 243 243]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  72%|███████▏  | 23/32 [00:09<00:02,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[245 244 242 ... 244 244 244]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  75%|███████▌  | 24/32 [00:10<00:02,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[246 246 247 ... 248 248 248]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  78%|███████▊  | 25/32 [00:10<00:02,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[235 245 242 ... 243 243 243]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  81%|████████▏ | 26/32 [00:10<00:01,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250 250 250 ... 250 250 250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  84%|████████▍ | 27/32 [00:11<00:01,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[251 251 251 ... 251 251 251]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  88%|████████▊ | 28/32 [00:11<00:01,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[240 241 242 ... 242 240 240]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  91%|█████████ | 29/32 [00:11<00:01,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[247 247 247 ... 247 247 247]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  94%|█████████▍| 30/32 [00:12<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[251 251 251 ... 251 251 251]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "进度:  97%|█████████▋| 31/32 [00:12<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[244 239 252 ... 245 245 245]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "进度: 100%|██████████| 32/32 [00:13<00:00,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[244 244 244 ... 244 244 244]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "DIR = \"./CaptchaImage/\"\n",
    "\n",
    "def decodeJPG(filename, sess, writer):\n",
    "    image = tf.gfile.FastGFile(os.path.join(DIR, filename), 'rb').read()\n",
    "    # 将图片解码，解成张量  image is a 3-D uint8 or uint16 Tensor of shape [height, width, channels]\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    # 转化为灰度图\n",
    "    image = sess.run(tf.image.rgb_to_grayscale(image))\n",
    "    # 将图片转化为1维\n",
    "    # 这一步不run的话，返回tensor变量，run了之后返回ndarray\n",
    "    image = sess.run(tf.reshape(image, [-1]))\n",
    "    print(image)\n",
    "    # 获得标签\n",
    "    names = filename.split('.')\n",
    "    label = sess.run(tf.reshape([int(i) for i in list(names[0])],[-1]))\n",
    "    # 将一个验证码图片转化为Example Protocol Buffer\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'input_pixels_num': _int64_feature(160 * 60),\n",
    "        'label': _bytes_feature(label.tostring()),\n",
    "        'image': _bytes_feature(image.tostring())\n",
    "    }))\n",
    "    writer.write(example.SerializeToString())\n",
    "   \n",
    "          \n",
    "filename = \"./CaptchaRecognize/output.tfrecords\"\n",
    "          \n",
    "with tf.Session() as sess:\n",
    "    # 创建一个writer来写tfrecord文件\n",
    "    with tf.python_io.TFRecordWriter(filename) as writer:\n",
    "        for root, dirs, files in os.walk(DIR):\n",
    "            # 定义进度条\n",
    "            with tqdm(total=32, desc='进度') as bar:\n",
    "                for file in files[0:32]:\n",
    "                    decodeJPG(file, sess=sess, writer=writer)\n",
    "                    bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-c8603e3006bb>:3: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "WARNING:tensorflow:From <ipython-input-2-c8603e3006bb>:5: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From D:\\Environment\\Anaconda3\\envs\\tfenv3.6-gpu\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From D:\\Environment\\Anaconda3\\envs\\tfenv3.6-gpu\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From D:\\Environment\\Anaconda3\\envs\\tfenv3.6-gpu\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From D:\\Environment\\Anaconda3\\envs\\tfenv3.6-gpu\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-2-c8603e3006bb>:22: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "[array([250, 243, 245, ..., 243, 242, 253], dtype=uint8), array([0, 0, 0, 0])]\n",
      "[array([250, 250, 250, ..., 250, 250, 250], dtype=uint8), array([0, 0, 0, 1])]\n",
      "[array([246, 246, 246, ..., 249, 245, 243], dtype=uint8), array([0, 0, 0, 2])]\n",
      "[array([245, 246, 237, ..., 244, 244, 244], dtype=uint8), array([0, 0, 0, 3])]\n",
      "[array([243, 243, 244, ..., 244, 244, 244], dtype=uint8), array([0, 0, 0, 4])]\n"
     ]
    }
   ],
   "source": [
    "# 读取tfrecords文件\n",
    "# 创建一个reader对象\n",
    "reader = tf.TFRecordReader()\n",
    "# 创建一个队列维护输入文件列表\n",
    "filename_queue = tf.train.string_input_producer([\"./CaptchaRecognize/output.tfrecords\"])\n",
    "_, serialized_example = reader.read(filename_queue)\n",
    "# 使用parse_single_example 一次只取一个数据\n",
    "# 使用parse_example 可以取多个\n",
    "feature = tf.parse_single_example(serialized_example,\n",
    "                                 features={\n",
    "        'input_pixels_num':tf.FixedLenFeature([],tf.int64),\n",
    "        'label': tf.FixedLenFeature([],tf.string),\n",
    "        'image': tf.FixedLenFeature([],tf.string) \n",
    "                                 })\n",
    "image = tf.decode_raw(feature['image'],tf.uint8)\n",
    "label = tf.decode_raw(feature['label'],tf.int32)\n",
    "# label = tf.reshape(tf.cast(label,tf.float32), [-1])\n",
    "pixnum = feature['input_pixels_num']\n",
    "sess = tf.Session()\n",
    "# # 启动多线程处理输入数据\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(5):\n",
    "#     img = sess.run(image)\n",
    "#     im = sess.run(tf.reshape(img,[60,160]))\n",
    "#     plt.figure(1)\n",
    "#     plt.imshow(im)\n",
    "#     plt.show()\n",
    "   print(sess.run([image,label]))\n",
    "\n",
    "# sess.close() 上面程序应该是自动关闭了sess，手动关闭会报错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建batch读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[246. 246. 246. ... 249. 245. 243.]\n",
      " [245. 245. 245. ... 232. 239. 238.]\n",
      " [250. 250. 250. ... 250. 250. 250.]\n",
      " ...\n",
      " [243. 243. 243. ... 243. 243. 243.]\n",
      " [246. 246. 246. ... 246. 246. 246.]\n",
      " [249. 243. 250. ... 246. 246. 246.]] [[0. 0. 0. 2.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 8.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 1. 8.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 2. 8.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 2. 8.]\n",
      " [0. 0. 1. 6.]\n",
      " [0. 0. 3. 0.]\n",
      " [0. 0. 3. 1.]\n",
      " [0. 0. 2. 7.]\n",
      " [0. 0. 2. 7.]\n",
      " [0. 0. 2. 4.]\n",
      " [0. 0. 2. 0.]\n",
      " [0. 0. 2. 1.]\n",
      " [0. 0. 2. 0.]\n",
      " [0. 0. 1. 6.]]\n",
      "[[247. 247. 248. ... 249. 249. 249.]\n",
      " [251. 251. 251. ... 253. 251. 249.]\n",
      " [249. 251. 246. ... 251. 251. 251.]\n",
      " ...\n",
      " [245. 245. 245. ... 232. 239. 238.]\n",
      " [249. 251. 246. ... 251. 251. 251.]\n",
      " [247. 247. 247. ... 247. 247. 247.]] [[0. 0. 1. 5.]\n",
      " [0. 0. 1. 2.]\n",
      " [0. 0. 0. 9.]\n",
      " [0. 0. 0. 6.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 2. 8.]\n",
      " [0. 0. 2. 4.]\n",
      " [0. 0. 2. 2.]\n",
      " [0. 0. 1. 9.]\n",
      " [0. 0. 1. 6.]\n",
      " [0. 0. 1. 3.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 0. 8.]\n",
      " [0. 0. 0. 4.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 2. 8.]\n",
      " [0. 0. 2. 4.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 9.]\n",
      " [0. 0. 2. 8.]]\n",
      "(20, 9600)\n"
     ]
    }
   ],
   "source": [
    "image = tf.decode_raw(feature['image'],tf.uint8)\n",
    "image.set_shape([9600])\n",
    "image = tf.cast(image,tf.float32)\n",
    "label = tf.decode_raw(feature['label'],tf.int32)\n",
    "label.set_shape([4])\n",
    "label = tf.cast(label,tf.float32)\n",
    "# sess = tf.Session()\n",
    "# #将数据转化为实数\n",
    "# img_data = tf.image.convert_image_dtype(image,dtype=tf.float32)\n",
    "# print(sess.run(img_data))\n",
    "# sess.close()\n",
    "# # 调整图像大小\n",
    "# image = tf.image.resize_images(img_data,[60,160],method=0)\n",
    "\n",
    "# sess.close()\n",
    "batch_size = 20\n",
    "capacity = 1000 + 3 * batch_size\n",
    "# input_queue = tf.train.slice_input_producer([image, label], shuffle=False) \n",
    "example_batch, label_batch = tf.train.batch(\n",
    "[image, label],batch_size= batch_size,capacity=capacity)\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    # 启动多线程处理输入数据\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "    for i in range(2):\n",
    "        cur_example_batch,cur_label_batch = sess.run([example_batch, label_batch])\n",
    "#         cur_example_batch,cur_label_batch = sess.run([image,label])\n",
    "        print(cur_example_batch,cur_label_batch)\n",
    "    print(cur_example_batch.shape)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建卷积神经网络进行验证码图片的识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0] [0 0 2 0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "filename = '0000'\n",
    "filename2 = '0020'\n",
    "names = filename.split('.')\n",
    "names2 = filename2.split('.')\n",
    "label = [int(i) for i in list(names[0])]\n",
    "label2 = [int(i) for i in list(names2[0])]\n",
    "l = tf.reshape(label,[-1])\n",
    "l2 = tf.reshape(label2,[-1])\n",
    "r1,r2 = sess.run([l,l2])\n",
    "print(r1,r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.floa32,[None,9600])\n",
    "y = tf.placeholder(tf.float32,[None,4])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
